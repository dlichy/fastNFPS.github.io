
<!-- saved from url=(0037)https://guanyingc.github.io/SDPS-Net/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script src="./Self-calibrating Deep Photometric Stereo Networks_files/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
body {
    font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
    font-weight:300;
    font-size:18px;
    margin-left: auto;
    margin-right: auto;
    width: 1000px;
}	
h1 {
    font-weight:300;
}

.disclaimerbox {
    background-color: #eee;		
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
}

video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
}

img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
}

img.rounded {
    border: 0px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
}

a:link,a:visited
{
    color: #1367a7;
    text-decoration: none;
}
a:hover {
    color: #208799;
  }

  td.dl-link {
      height: 160px;
      text-align: center;
      font-size: 22px;
  }

  .vert-cent {
      position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
      border: 0;
      height: 1px;
      background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>



<title>Fast Light-Weight Near-Field Photometric Stereo</title>
<meta property="og:image" content="https://github.com/dlichy/ShapeAndMaterial"> <!--TODO-->
<!--<meta property="og:title" content="Self-calibrating Deep Photometric Stereo Networks, In CVPR 2019.">-->
</head>

<body>
<br>
<center>
    <span style="font-size:42px">Fast Light-Weight Near-Field Photometric Stereo</span><br>
    <table align="center" width="900px">
        <tbody><tr>
            <td align="center" width="900px">
                <span style="font-size:22px"><a href="http://www.cs.umd.edu/~dlichy/">Daniel Lichy<sup>1</sup></a></span>  
                <span style="font-size:22px"><a href="https://homes.cs.washington.edu/~soumya91/">Soumyadip Sengupta<sup>2</sup></a></span>  
                <span style="font-size:22px"><a href="http://www.cs.umd.edu/~djacobs/">David W. Jacobs<sup>1</sup></a></span>  
            </td>
        </tr>
    </tbody></table>
    <table align="center" width="800px">
        <tbody><tr><td align="center" width="300px">
            <span style="font-size:21px"><sup>1</sup>Univerity of Maryland <sup>2</sup>University of Washington</span> <br>
        </td>
    </tr></tbody></table>
    <br>
    <table align="center" width="900px">
        <tbody><tr>
            <td align="center" width="900px">
                <center>
                    <span style="font-size:22px"><a href="https://github.com">Code (coming 4/4/22)</a></span>    
                    <span style="font-size:22px"><a href="https://arxiv.org/abs/2203.16515">Paper [CVPR 2022]</a> </span>    
                    <br>
            </td>
        </tr>
    </tbody></table>
</center>
<br>


<center>
<img src="./images/teaser_v3.png" style="float: middle;"  height="220" width="1050" />
</center>

<hr>

<center><h1>Abstract</h1></center><p>
	We introduce the first end-to-end learning-based solution to near-field Photometric Stereo (PS), where the light sources are close to the object of interest. This setup is especially useful for reconstructing large immobile objects. Our method is fast, producing a mesh from 52 512×384 resolution images in about 1 second on a commodity GPU, thus potentially unlocking several AR/VR applications. Existing approaches rely on optimization coupled with a far-field PS network operating on pixels or small patches. Using optimization makes these approaches slow and memory intensive (requiring 17GB GPU and 27GB of CPU memory) while using only pixels or patches makes them highly susceptible to noise and calibration errors. To address these issues, we develop a recursive multi-resolution scheme to estimate surface normal and depth maps of the whole image at each step. The predicted depth map at each scale is then used to estimate `per-pixel lighting' for the next scale. This design makes our approach almost 45× faster and 2<sup>∘</sup> more accurate (11.3<sup>∘</sup> vs. 13.3<sup>∘</sup> Mean Angular Error) than the state-of-the-art near-field PS reconstruction technique, which uses iterative optimization. 
    </p><table align="center" width="900px">
    
    
</table>
<hr>



<center><h1>Result on LUCES</h1></center>

<table align="center">
    <tbody><tr>
        <td align="center" width="1000px">
            <!--<img class="round" style="width:1000px" src="./images/tweet1.mp4">-->
            <video width="860" height="540" autoplay muted loop>
            	<source src="./images/tweet1.mp4">
            </video>
        </td>
    </tr>
    <tr>
        <td>
        <p>3D results on the LUCES dataset.</p>
        </td>
    </tr>
</tbody></table>

<table align="center">
<tbody><tr>
        <td align="center" width="400px">
           <img class="center" style="width:600px" src="./images/luces_normal_cal.png">
          
        </td>
    </tr>
    <tr>
        <td>
        <p><br>Calibrated normal estimation on the LUCES dataset.</p>
        </td>
    </tr>
</tbody></table>

<hr>



<center><h1>Uncalibrated Flashlight Capture</h1></center>


<table align="center">
    <tbody><tr>
        <td align="center" width="1000px">
            <video width="860" height="540" autoplay muted loop>
            	<source src="./images/couch_only.mp4">
            </video>
        </td>
    </tr>
    <tr>
        <td>
        <p></p>
        </td>
    </tr>
</tbody></table>
    
<hr>

<center><h1>Single Image Face Capture</h1></center>
<table align="center">
    <tbody><tr>
        <td align="center" width="1000px">
            <video width="860" height="540" autoplay muted loop>
            	<source src="./images/face_only.mp4">
            </video>
        </td>
    </tr>
    <tr>
        <td>
        <p>Our model can be easily modified to work on a single selfie with flash</p>
        </td>
    </tr>
</tbody></table>
    


<hr>
<center><h1>Code and Model</h1></center>
    <center><h3>Our code, trained model, and data will be made publicly available on April 4 !</h3></center>
<hr>

<table align="center" width="1000px">
    <tbody><tr>
        <td width="300px">
           <left>
            <center><h1>Acknowledgments</h1></center>
		<center> This research is supported by the National Science Foundation under grant no. IIS-1910132.</center>
            </left>
        </td>
    </tr>
</tbody></table>
<br>

<p style="text-align:center;font-size:16px;">
    Webpage template borrowed from <a href="https://guanyingc.github.io/SDPS-Net/">Self-calibrating Deep Photometric Stereo Networks</a>.
</p>


</body></html>
